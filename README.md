# Privacy Risks of Large Language Models

This repository is a collection of links to papers and code repositories used in our survey on privacy risks of LLMs.

## Table of Contents

- [Privacy Risks of LLMs](#privacy-risks-of-large-language-models)
  - [Memorization](#memorization)


## Citation

```
TODO: Fill in once on Arxiv
```

# Memorization

| **Paper Title** | **Year** | **Author** | **Code** |
| --------------- | :----: | ---- | :----: |
| [Emergent and Predictable Memorization in Large Language Models](https://arxiv.org/abs/2304.11158) | 2023 | Biderman et al. | [[Code]](https://github.com/EleutherAI/pythia) |
| [Measuring Forgetting of Memorized Training Examples](https://arxiv.org/abs/2207.00099) | 2023 | Jagielski et al. |  | 